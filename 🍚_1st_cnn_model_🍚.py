# -*- coding: utf-8 -*-
"""🍚 1st CNN Model 🍚

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gS0SzUhKPMnb0-yWnFvs_QJbj5XJTrPF

# **Accessing the Rice Image Files in Google Drive**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

"""# **Imports**"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow.keras.preprocessing import image_dataset_from_directory
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from pathlib import Path
import tensorflow as tf
import seaborn as sns
import pandas as pd
import numpy as np
import itertools
import os.path
import os
# %matplotlib inline

"""# **Data Preprocessing**"""

BATCH_SIZE = 64
IMG_SIZE = (224, 224)

train_dataset = image_dataset_from_directory('/gdrive/MyDrive/_rice/train',
                                             shuffle=True,
                                             batch_size=BATCH_SIZE,
                                             image_size=IMG_SIZE)

validation_dataset = image_dataset_from_directory('/gdrive/MyDrive/_rice/validation',
                                                  shuffle=True,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_SIZE)

testing_dataset = image_dataset_from_directory('/gdrive/MyDrive/_rice/testing',
                                                  shuffle=False,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_SIZE)

"""# **Training Datasets Classnames**"""

class_names = train_dataset.class_names
print(class_names)

"""# **Visualization of the Images and Labels from the Training Set:**"""

class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(16):
    ax = plt.subplot(6, 6, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""# **Use Data Augmentation**"""

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),
  tf.keras.layers.experimental.preprocessing.RandomFlip('vertical'),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
])

"""# **Visualization of the Augmented Images**"""

for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[2]
  
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')

"""# **Creation/Instantiation of the Layer using MobineNetV2 Pretrained Model**"""

pretrained_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)
pretrained_model.trainable = False

"""**MobileNetV2 Architecture**"""

print(pretrained_model.summary())



"""# **Building the Rice Classifier Model**"""

inputs = pretrained_model.input                                           
x = data_augmentation(inputs)                                             
x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)
x = tf.keras.layers.Dropout(0.2)(x)                                       
outputs = tf.keras.layers.Dense(5, activation='softmax')(x)               
model = tf.keras.Model(inputs, outputs)

"""# **Architecture of the Rice Classifier Model**"""

print(model.summary())

"""# Training and Validating the Rice Classifier Model"""

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_dataset,
    validation_data=validation_dataset,
    epochs=10,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

"""# Learning Curves of the Training Accuracy and Loss 

# Learning Curves of the Validation Accuracy and Loss
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""# **Evaluating the Rice Classifier Model with the Entire Test Datasets**"""

results = model.evaluate(testing_dataset, verbose=0)
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

"""# **Prediction of the Entire Test Datasets**"""

predictions = np.argmax(model.predict(testing_dataset), axis=1)

"""# **Getting the Labels of the Entire Test Datasets**"""

test_label = np.concatenate([y for x, y in testing_dataset], axis=0)

"""# **Confusion Matrix Without Normalization**"""

cm = confusion_matrix(test_label, predictions)

def plot_confusion_matrix(cm, classes,
                          normalize= False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
   
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


cm_plot_labels = ['160','Alimona', 'Dinorado', 'Red V10', 'Sinandomeng']
plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')

"""# **Confusion Matrix With Normalization**"""

cm = confusion_matrix(test_label, predictions)

def plot_confusion_matrix(cm, classes,
                          normalize= True,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
   
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


cm_plot_labels = ['160','Alimona', 'Dinorado', 'Red V10', 'Sinandomeng']
plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')

"""# **Saving the Entire Model**"""

import numpy as np
import tensorflow as tf
from tensorflow import keras

model.save("/gdrive/MyDrive/Colab Notebooks/my_model")

"""# **Loading the Model Back**"""

from tensorflow import keras
model = keras.models.load_model('/gdrive/MyDrive/Colab Notebooks/my_model')

"""# **New Test Datasets**"""

new_testing_dataset = image_dataset_from_directory('/gdrive/MyDrive/another_batch_of_test_datasets',
                                                  shuffle=False,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_SIZE)

"""# **Evaluation of the New Test Datasets**"""

results = model.evaluate(new_testing_dataset, verbose=0)
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

"""# **Prediction with the Entire New Test Datasets**"""

predictions = np.argmax(model.predict(new_testing_dataset), axis=1)

"""# **Getting the Labels of the Entire Test Datasets**"""

test_label = np.concatenate([y for x, y in new_testing_dataset], axis=0)

"""# **Use Confusion Matrix with the New Test Datasets**"""

#Confusion Matrix Without Normalization
cm = confusion_matrix(test_label, predictions)

def plot_confusion_matrix(cm, classes,
                          normalize= False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
   
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


cm_plot_labels = ['160','Alimona', 'Dinorado', 'Red V10', 'Sinandomeng']
plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')

"""# **Use Confusion Matrix With Normalization**"""

#Confusion Matrix Without Normalization
cm = confusion_matrix(test_label, predictions)

def plot_confusion_matrix(cm, classes,
                          normalize= True,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
   
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


cm_plot_labels = ['160','Alimona', 'Dinorado', 'Red V10', 'Sinandomeng']
plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')

"""# **Save the Model**"""

model.save("/gdrive/MyDrive/Colab Notebooks/my_model2")

"""# **Live Demo Session Evaluating the Extra Datasets**

# **Load Back the Model**
"""

from tensorflow import keras
model = keras.models.load_model('/gdrive/MyDrive/Colab Notebooks/my_model2')

live_demo_testing_dataset = image_dataset_from_directory('/gdrive/MyDrive/Live_Testing_Datasets',
                                                  shuffle=False,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_SIZE)

"""# **Evaluation of the Extra Test Datasets in Live Demo Session**"""

results = model.evaluate(live_demo_testing_dataset, verbose=0)
print("Test Accuracy: {:.2f}%".format(results[1] * 100))